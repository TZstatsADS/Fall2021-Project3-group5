{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d23f032",
   "metadata": {},
   "source": [
    "Model1 training on 50000 noised labels: 0.4395 val_accuracy on 10 epochs\n",
    "\n",
    "Model2 training on 50000 cleaned labels + vgg16 features extraction: 0.5717 val_acc on 10 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75feea41",
   "metadata": {},
   "source": [
    "## 0. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674d5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\31557\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\31557\\anaconda3\\lib\\site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\31557\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "!pip install opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras import optimizers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D,Activation,GlobalAveragePooling2D,Input,Dropout,concatenate,BatchNormalization,Concatenate\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73959dd",
   "metadata": {},
   "source": [
    "## 1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c686f07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10), (10000, 10), (10000, 32, 32, 3), (50000, 32, 32, 3), (50000, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "\n",
    "target_vec = np.empty((n_img,10))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    if i < 10000:\n",
    "        target_vec[i][int(clean_labels[i])-1] = 1\n",
    "    else:\n",
    "        target_vec[i][int(noisy_labels[i])-1] = 1\n",
    "\n",
    "y_train_clean =  to_categorical(clean_labels, 10)\n",
    "y_train_noisy =  to_categorical(noisy_labels[:10000],10)\n",
    "\n",
    "x_train_clean = imgs[:10000].astype(\"float16\")/255\n",
    "x_train_full = imgs.astype(\"float16\")/255\n",
    "\n",
    "x_train_clean.astype(\"float16\")\n",
    "x_train_full.astype(\"float16\")\n",
    "\n",
    "y_train_full = target_vec\n",
    "\n",
    "y_train_clean.shape, y_train_noisy.shape, x_train_clean.shape, x_train_full.shape,y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6b00a",
   "metadata": {},
   "source": [
    "## Model 1, base model\n",
    "\n",
    "Trained on clean images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20433753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31557\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 12s 44ms/step - loss: 2.1612 - accuracy: 0.1945 - val_loss: 2.0092 - val_accuracy: 0.2675\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 1.9732 - accuracy: 0.2707 - val_loss: 1.8857 - val_accuracy: 0.3230\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.8824 - accuracy: 0.3040 - val_loss: 1.8050 - val_accuracy: 0.3320\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.8181 - accuracy: 0.3228 - val_loss: 1.7469 - val_accuracy: 0.3625\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.7691 - accuracy: 0.3458 - val_loss: 1.6842 - val_accuracy: 0.3850\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.7350 - accuracy: 0.3599 - val_loss: 1.6450 - val_accuracy: 0.4085\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 1.6886 - accuracy: 0.3784 - val_loss: 1.6192 - val_accuracy: 0.4055\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 1.6753 - accuracy: 0.3819 - val_loss: 1.5926 - val_accuracy: 0.4325\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.6473 - accuracy: 0.3924 - val_loss: 1.5963 - val_accuracy: 0.4210\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 1.6270 - accuracy: 0.4045 - val_loss: 1.5414 - val_accuracy: 0.4210\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.5970 - accuracy: 0.4160 - val_loss: 1.5189 - val_accuracy: 0.4385\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.5860 - accuracy: 0.4199 - val_loss: 1.5077 - val_accuracy: 0.4535\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 1.5609 - accuracy: 0.4314 - val_loss: 1.4881 - val_accuracy: 0.4575\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.5473 - accuracy: 0.4369 - val_loss: 1.4860 - val_accuracy: 0.4580\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 1.5307 - accuracy: 0.4470 - val_loss: 1.4652 - val_accuracy: 0.4605\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 1.5323 - accuracy: 0.4454 - val_loss: 1.4304 - val_accuracy: 0.4755\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.5053 - accuracy: 0.4505 - val_loss: 1.4348 - val_accuracy: 0.4800\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.4925 - accuracy: 0.4554 - val_loss: 1.4244 - val_accuracy: 0.4675\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.4779 - accuracy: 0.4605 - val_loss: 1.4847 - val_accuracy: 0.4675\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 1.4732 - accuracy: 0.4599 - val_loss: 1.3829 - val_accuracy: 0.5005\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h1'\n",
    "\n",
    "\n",
    "# _, (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# RMSprop\n",
    "opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "#     model.fit(x_train_clean, y_train_clean,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(X_test, y_test),\n",
    "#               shuffle=True)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "    datagen.fit(x_train_clean)\n",
    "\n",
    "    \n",
    "    model.fit(datagen.flow(x_train_clean, y_train_clean, batch_size=32,subset='training'),\n",
    "         validation_data=datagen.flow(x_train_clean, y_train_clean,batch_size=8, subset='validation'),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d1158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa6f7097",
   "metadata": {},
   "source": [
    "Trained on noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b862d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 56s 44ms/step - loss: 2.2857 - accuracy: 0.1362 - val_loss: 2.1705 - val_accuracy: 0.2893\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 2.2681 - accuracy: 0.1575 - val_loss: 2.1037 - val_accuracy: 0.3265\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 2.2574 - accuracy: 0.1696 - val_loss: 2.0969 - val_accuracy: 0.3470\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 56s 44ms/step - loss: 2.2510 - accuracy: 0.1789 - val_loss: 2.0330 - val_accuracy: 0.3728\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 56s 44ms/step - loss: 2.2459 - accuracy: 0.1834 - val_loss: 1.9933 - val_accuracy: 0.3901\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.2416 - accuracy: 0.1871 - val_loss: 1.9496 - val_accuracy: 0.4061\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.2395 - accuracy: 0.1922 - val_loss: 1.9571 - val_accuracy: 0.3982\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.2331 - accuracy: 0.2007 - val_loss: 1.9472 - val_accuracy: 0.4155\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.2317 - accuracy: 0.2000 - val_loss: 1.9399 - val_accuracy: 0.4276\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 2.2307 - accuracy: 0.2021 - val_loss: 1.8997 - val_accuracy: 0.4395\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h1_noisy'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# RMSprop\n",
    "opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "#     model.fit(x_train_clean, y_train_clean,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(X_test, y_test),\n",
    "#               shuffle=True)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "    datagen.fit(x_train_full)\n",
    "\n",
    "    \n",
    "    model.fit(datagen.flow(x_train_full, y_train_full, batch_size=32,subset='training'),\n",
    "         validation_data=datagen.flow(x_train_full, y_train_full,batch_size=8, subset='validation'),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4d8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46ff11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e37bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d11cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2095c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b95e726f",
   "metadata": {},
   "source": [
    "## 3. Model 2, cleaning label + classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451ca9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e8f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 15s 176ms/step - loss: 199.3929 - acc: 0.2576\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 159.1855 - acc: 0.4210\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 139.7927 - acc: 0.4955\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 130.9886 - acc: 0.5193\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 121.4623 - acc: 0.5514\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 115.6424 - acc: 0.5746\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 114.3628 - acc: 0.5739\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 110.2011 - acc: 0.5871\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 105.6384 - acc: 0.6029\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 103.2040 - acc: 0.6111\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 103.2820 - acc: 0.6106\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 101.2678 - acc: 0.6161\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 99.7717 - acc: 0.6209\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 97.5832 - acc: 0.6308\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 95.0340 - acc: 0.6393\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 92.8881 - acc: 0.6475\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 94.1384 - acc: 0.6429\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 93.9822 - acc: 0.6407\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 92.9623 - acc: 0.6460\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 91.4338 - acc: 0.6519\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 90.3486 - acc: 0.6549\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 89.5134 - acc: 0.6579\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 87.5745 - acc: 0.6636\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 86.3543 - acc: 0.6694\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 13s 165ms/step - loss: 87.4860 - acc: 0.6649\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 87.6280 - acc: 0.6640\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 85.8069 - acc: 0.6710\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 13s 166ms/step - loss: 86.0332 - acc: 0.6706\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 13s 167ms/step - loss: 85.0942 - acc: 0.6733\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 13s 167ms/step - loss: 84.3447 - acc: 0.6776\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 85.0329 - acc: 0.6740\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 84.7847 - acc: 0.6737\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 82.7962 - acc: 0.6833\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 83.4169 - acc: 0.6788\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 83.1293 - acc: 0.6811\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 81.9275 - acc: 0.6844\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 81.8976 - acc: 0.6861\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 83.1223 - acc: 0.6800\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 81.6411 - acc: 0.6859\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 81.7050 - acc: 0.6850\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 81.9031 - acc: 0.6863\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 80.7441 - acc: 0.6888\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 82.6372 - acc: 0.6830\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 13s 165ms/step - loss: 84.5582 - acc: 0.6734\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 81.7310 - acc: 0.6840\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 81.6453 - acc: 0.6846\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 80.8227 - acc: 0.6890\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 78.7967 - acc: 0.6974\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 14s 171ms/step - loss: 79.0381 - acc: 0.6958\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 13s 165ms/step - loss: 81.0601 - acc: 0.6877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa62be7190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# base_cnn = model.layers[-5:]\n",
    "\n",
    "# for layer in base_cnn:\n",
    "#     layer.trainable=False\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "base_model_vgg16=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(32,32,3)),pooling=\"max\" ) \n",
    "base_model_vgg16.trainable = False\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "base_model_vgg19=VGG19(weights='imagenet',include_top=False,input_tensor=Input(shape=(32,32,3)),pooling=\"max\" ) \n",
    "base_model_vgg19.trainable = False\n",
    "\n",
    "class LastLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.output_dim = 10\n",
    "        super(LastLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(LastLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, gxy, y):\n",
    "        return K.maximum(K.minimum(gxy + y, 1),0)\n",
    "\n",
    "\n",
    "def label_loss(true_label, cleaned_label):\n",
    "    return K.sum(K.abs(cleaned_label - true_label))\n",
    "\n",
    "\n",
    "\n",
    "def model_2(base_cnn):\n",
    "    \n",
    "    img_input = Input(shape=(32, 32, 3))\n",
    "    noisy_label = Input(shape = (10))\n",
    "    \n",
    "    img_vec = base_cnn(img_input)\n",
    "    \n",
    "    noisy_l = Dense(10)(noisy_label)\n",
    "    img_vec = Dense(256)(img_vec)\n",
    "\n",
    "    # combine\n",
    "    x = Concatenate(axis=-1)([noisy_l, img_vec])\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation = 'relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out = Dense(10, activation = 'softmax')(x)\n",
    "    # out = LastLayer()(out, noisy_label)\n",
    "    \n",
    "    model = Model([img_input, noisy_label], out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model2 = model_2(base_model_vgg16)\n",
    "\n",
    "Adam = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "model2.compile(loss=label_loss, metrics=['acc'], optimizer=Adam)\n",
    "\n",
    "model2.fit([x_train_clean, y_train_noisy], y_train_clean , batch_size = 128, epochs = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ace0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e567e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_label = model2.predict([x_train_full,y_train_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e95ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c68e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_labels = np.argmax(cleaned_label,axis=1 )\n",
    "cleaned_labels = to_categorical(cleaned_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1c84e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_labels[0], sum(cleaned_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e2efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c026b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5a1e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 95s 75ms/step - loss: 1.7597 - acc: 0.3938 - val_loss: 1.3234 - val_acc: 0.5429\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 93s 74ms/step - loss: 1.5055 - acc: 0.4800 - val_loss: 1.2936 - val_acc: 0.5474\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 94s 75ms/step - loss: 1.4644 - acc: 0.4961 - val_loss: 1.2607 - val_acc: 0.5648\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 95s 76ms/step - loss: 1.4448 - acc: 0.5064 - val_loss: 1.2510 - val_acc: 0.5684\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 93s 74ms/step - loss: 1.4418 - acc: 0.5047 - val_loss: 1.2619 - val_acc: 0.5600\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 94s 75ms/step - loss: 1.4272 - acc: 0.5104 - val_loss: 1.2698 - val_acc: 0.5687\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 96s 77ms/step - loss: 1.4223 - acc: 0.5127 - val_loss: 1.2463 - val_acc: 0.5690\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 96s 77ms/step - loss: 1.4234 - acc: 0.5126 - val_loss: 1.2355 - val_acc: 0.5682\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 93s 74ms/step - loss: 1.4124 - acc: 0.5162 - val_loss: 1.2271 - val_acc: 0.5769\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 92s 74ms/step - loss: 1.4060 - acc: 0.5186 - val_loss: 1.2310 - val_acc: 0.5717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa7595adc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def model_3(base_cnn):\n",
    "    \n",
    "    img_input = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    img_vec = base_cnn(img_input)\n",
    "    \n",
    "    x = Dense(256)(img_vec)\n",
    "\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation = 'relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out = Dense(10, activation = 'softmax')(x)\n",
    "    # out = LastLayer()(out, noisy_label)\n",
    "    \n",
    "    model = Model(img_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "model3 = model_3(base_model_vgg16)\n",
    "\n",
    "loss = tf.keras.losses\n",
    "\n",
    "Adam = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "model3.compile(loss=\"categorical_crossentropy\", metrics=['acc'], optimizer=Adam)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "datagen.fit(x_train_full)\n",
    "\n",
    "model3.fit(datagen.flow(x_train_full, cleaned_labels, batch_size=32,subset='training'),\n",
    "           validation_data=datagen.flow(x_train_full, cleaned_labels,batch_size=8, subset='validation'),\n",
    "           batch_size = 128, \n",
    "           epochs = 10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29bb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c603214",
   "metadata": {},
   "source": [
    "## Add tensorboard for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# model = label_nn()\n",
    "tenserboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# history1 = model.fit([clean_imgs, noisy], clean, batch_size = 128, epochs =5, callbacks = [tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b409f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 90s 71ms/step - loss: 1.7784 - acc: 0.3805 - val_loss: 1.3355 - val_acc: 0.5464\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 91s 73ms/step - loss: 1.5408 - acc: 0.4642 - val_loss: 1.2870 - val_acc: 0.5550\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 90s 72ms/step - loss: 1.4921 - acc: 0.4805 - val_loss: 1.2787 - val_acc: 0.5583\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 94s 75ms/step - loss: 1.4679 - acc: 0.4886 - val_loss: 1.2504 - val_acc: 0.5650\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 97s 78ms/step - loss: 1.4614 - acc: 0.4957 - val_loss: 1.2563 - val_acc: 0.5683\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 93s 75ms/step - loss: 1.4462 - acc: 0.5005 - val_loss: 1.2415 - val_acc: 0.5715\n",
      "Epoch 7/10\n",
      " 628/1250 [==============>...............] - ETA: 35s - loss: 1.4345 - acc: 0.5030"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-87e9d352bd00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m model4.fit(datagen.flow(x_train_full, cleaned_labels, batch_size=32,subset='training'),\n\u001b[0m\u001b[0;32m     40\u001b[0m            \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleaned_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m            \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_4(base_cnn):\n",
    "    \n",
    "    img_input = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    img_vec = base_cnn(img_input)\n",
    "    \n",
    "\n",
    "    x = Dense(256, activation = 'relu')(img_vec)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation = 'relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out = Dense(10, activation = 'softmax')(x)\n",
    "    # out = LastLayer()(out, noisy_label)\n",
    "    \n",
    "    model = Model(img_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "model4 = model_4(base_model_vgg16)\n",
    "\n",
    "# loss = tf.keras.losses\n",
    "\n",
    "Adam = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", metrics=['acc'], optimizer=Adam)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "datagen.fit(x_train_full)\n",
    "\n",
    "file_path = \"../output/model4_history1\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "\n",
    "callback = [checkpoint, tenserboard]\n",
    "\n",
    "model4.fit(datagen.flow(x_train_full, cleaned_labels, batch_size=32,subset='training'),\n",
    "           validation_data=datagen.flow(x_train_full, cleaned_labels,batch_size=8, subset='validation'),\n",
    "           batch_size = 128,\n",
    "           callbacks=callback\n",
    "           epochs = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f3791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c59e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a3b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea2d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688f8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec32e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68913bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4af95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
